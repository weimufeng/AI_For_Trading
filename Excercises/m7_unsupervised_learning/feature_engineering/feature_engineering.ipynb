{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Labeling\n",
    "\n",
    "We'll use the price-volume data and generate features that we can feed into a model.  We'll use this notebook for all the coding exercises of this lesson, so please open this notebook in a separate tab of your browser.  \n",
    "\n",
    "Please run the following code up to and including \"Make Factors.\"  Then continue on with the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/3a/88b210db68e56854d0bcf4b38e165e03be377e13907746f825790f3df5bf/setuptools-59.6.0-py3-none-any.whl (952kB)\n",
      "\u001b[K    100% |████████████████████████████████| 962kB 14.1MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Found existing installation: setuptools 38.4.0\n",
      "    Uninstalling setuptools-38.4.0:\n",
      "      Successfully uninstalled setuptools-38.4.0\n",
      "Successfully installed setuptools-59.6.0\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/6d/6463d49a933f547439d6b5b98b46af8742cc03ae83543e4d7688c2420f8b/pip-21.3.1-py3-none-any.whl (1.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.7MB 5.4MB/s eta 0:00:01    76% |████████████████████████▌       | 1.3MB 28.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-21.3.1\n",
      "Collecting alphalens==0.3.2\n",
      "  Downloading alphalens-0.3.2.tar.gz (18.9 MB)\n",
      "     |████████████████████████████████| 18.9 MB 13.7 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.1.5)\n",
      "Requirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3)) (0.10.0)\n",
      "Collecting numpy==1.14.5\n",
      "  Downloading numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2 MB)\n",
      "     |████████████████████████████████| 12.2 MB 330 kB/s             \n",
      "\u001b[?25hCollecting pandas==0.18.1\n",
      "  Downloading pandas-0.18.1.zip (8.5 MB)\n",
      "     |████████████████████████████████| 8.5 MB 11.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly==2.2.3\n",
      "  Downloading plotly-2.2.3.tar.gz (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 10.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2017.3)\n",
      "Requirement already satisfied: requests==2.18.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.18.4)\n",
      "Collecting scipy==1.0.0\n",
      "  Downloading scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0 MB)\n",
      "     |████████████████████████████████| 50.0 MB 71 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.11.0)\n",
      "Collecting zipline===1.2.0\n",
      "  Downloading zipline-1.2.0.tar.gz (659 kB)\n",
      "     |████████████████████████████████| 659 kB 5.7 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting graphviz==0.9\n",
      "  Downloading graphviz-0.9-py2.py3-none-any.whl (16 kB)\n",
      "Collecting shap==0.25.2\n",
      "  Downloading shap-0.25.2.tar.gz (197 kB)\n",
      "     |████████████████████████████████| 197 kB 5.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.6/site-packages (from alphalens==0.3.2->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: seaborn>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from alphalens==0.3.2->-r requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from alphalens==0.3.2->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: IPython>=3.2.3 in /opt/conda/lib/python3.6/site-packages (from alphalens==0.3.2->-r requirements.txt (line 1)) (6.5.0)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2019.11.28)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (21.3.1)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (59.6.0)\n",
      "Collecting Logbook>=0.12.5\n",
      "  Downloading Logbook-1.5.3.tar.gz (85 kB)\n",
      "     |████████████████████████████████| 85 kB 2.5 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting requests-file>=1.4.1\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting pandas-datareader<0.6,>=0.2.1\n",
      "  Downloading pandas_datareader-0.5.0-py2.py3-none-any.whl (74 kB)\n",
      "     |████████████████████████████████| 74 kB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (0.4.1)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2\n",
      "  Downloading cyordereddict-1.0.0.tar.gz (138 kB)\n",
      "     |████████████████████████████████| 138 kB 6.5 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0\n",
      "  Downloading Bottleneck-1.3.5-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "     |████████████████████████████████| 351 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting contextlib2>=0.4.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1\n",
      "  Downloading bcolz-0.12.1.tar.gz (622 kB)\n",
      "     |████████████████████████████████| 622 kB 12.8 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (6.7)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (0.8.2)\n",
      "Collecting multipledispatch>=0.4.8\n",
      "  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.2.0->-r requirements.txt (line 14)) (1.0.7)\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 14)) (1.1.13)\n",
      "Collecting alembic>=0.7.7\n",
      "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "     |████████████████████████████████| 210 kB 9.3 MB/s            \n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting intervaltree>=2.1.0\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lru-dict>=1.1.4\n",
      "  Downloading lru_dict-1.1.8-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Collecting empyrical>=0.4.2\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "     |████████████████████████████████| 52 kB 1.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tables>=3.3.0\n",
      "  Downloading tables-3.7.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "     |████████████████████████████████| 6.0 MB 9.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from shap==0.25.2->-r requirements.txt (line 16)) (4.11.2)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting sqlalchemy>=1.0.8\n",
      "  Downloading SQLAlchemy-1.4.40-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 8.6 MB/s            \n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (1.0.15)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (4.3.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.7.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (4.3.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (0.2.0)\n",
      "Collecting requests-ftp\n",
      "  Downloading requests-ftp-0.3.1.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy>=1.0.8->zipline===1.2.0->-r requirements.txt (line 14)) (0.4.12)\n",
      "Collecting tables>=3.3.0\n",
      "  Downloading tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\n",
      "     |████████████████████████████████| 4.3 MB 7.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.1.7)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect->IPython>=3.2.3->alphalens==0.3.2->-r requirements.txt (line 1)) (0.5.2)\n",
      "Building wheels for collected packages: alphalens, pandas, plotly, zipline, shap, bcolz, cyordereddict, empyrical, intervaltree, Logbook, requests-ftp\n",
      "  Building wheel for alphalens (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alphalens: filename=alphalens-0.3.2-py3-none-any.whl size=18878479 sha256=3fea48d281b742c17357c38f0d1c564092b65602206e41a1cfaaccfd6086b94d\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/9e/b8/a502db514b9cf748687129d96fb1f8156f47ef6ab450abf4d0\n",
      "  Building wheel for pandas (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas: filename=pandas-0.18.1-cp36-cp36m-linux_x86_64.whl size=14622680 sha256=8b9a4f2e8ba187ccc7efe3f9af4407e664ed6ba90f7250846168d0b8b95085f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/6d/5e/614faed2b3130fc89c36e185e83a331098324e32d08f6bb2f3\n",
      "  Building wheel for plotly (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for plotly: filename=plotly-2.2.3-py3-none-any.whl size=1124681 sha256=822a7c54e85edd136b858826103c80e7cf6715afd603958e654ee5726af38ba6\n",
      "  Stored in directory: /root/.cache/pip/wheels/3b/63/08/bfacfd43d79c1851c5d03a6e8c27582203c5746fe00579b5db\n",
      "  Building wheel for zipline (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zipline: filename=zipline-1.2.0-cp36-cp36m-linux_x86_64.whl size=5583315 sha256=f6a946bd9365454141d0a943ee414afd1ef9ffd9bf88a0d989de4c7e436fccf1\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/13/88/164e4ac4e2662016300b12a0ab0920780bbb725120ccdb858a\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.25.2-cp36-cp36m-linux_x86_64.whl size=268056 sha256=08d757889fd739b05057e45cb165a969fbf6e1237036d843c70625f74cfd3636\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/7b/e9/aec94cd5b96b785253762c905f6a14dcb3e297129031a086d6\n",
      "  Building wheel for bcolz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bcolz: filename=bcolz-0.12.1-cp36-cp36m-linux_x86_64.whl size=1113530 sha256=785cee1fc8bb307e183d54705998587cf016bb5cc7f7363cc34aed282018f480\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/51/d6/173c1dabc3904530cd9527026946789e2a065b004916e5c5bb\n",
      "  Building wheel for cyordereddict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cyordereddict: filename=cyordereddict-1.0.0-cp36-cp36m-linux_x86_64.whl size=170937 sha256=bf0b566648e06730d3563f1c3d14d3dd24d7351d8a3bd24d82337b046b7ff73e\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/ff/1a/5f19b34a20e254f738ef53a8469e9e92ee13e66d54de3ea89c\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=41034 sha256=0c70775c188dcdc4cd22785495624d30a73549a78c0cf894ca8129f33e08f7cc\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/0b/5a/ca1ca63ffb9d995bd8f0d3a75f14e89d54e1b0caee61b68c02\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26495 sha256=57906a722f7667e910f05d4c07bc9db9bb87b64cf755f66bc66f2a88ad83675f\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/e6/3f/1616b381f981006664dd5123f06b231bbbb2e7d604a417e2fd\n",
      "  Building wheel for Logbook (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Logbook: filename=Logbook-1.5.3-cp36-cp36m-linux_x86_64.whl size=66992 sha256=d95f2f70c2d81d3112e9d4e72e2d93c84eeb4930c513ceff8629ef369d07bf15\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/4c/d7/c08e0670a3318441d3bd095149eb6e86e21656f102530ac8b6\n",
      "  Building wheel for requests-ftp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for requests-ftp: filename=requests_ftp-0.3.1-py3-none-any.whl size=10036 sha256=8070f7061d957bde99a906869378fe1526187cf6861d31e913ac57f3dadf3600\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e4/5d/72f7aad2c589cd6b0fa0c38feda872115bff8512a46d6c7b74\n",
      "Successfully built alphalens pandas plotly zipline shap bcolz cyordereddict empyrical intervaltree Logbook requests-ftp\n",
      "Installing collected packages: zipp, typing-extensions, numpy, requests-ftp, requests-file, pandas, importlib-metadata, sqlalchemy, sortedcontainers, scipy, pandas-datareader, importlib-resources, tables, multipledispatch, lru-dict, Logbook, intervaltree, empyrical, cyordereddict, contextlib2, bottleneck, bcolz, alembic, zipline, shap, plotly, graphviz, alphalens\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.1.13\n",
      "    Uninstalling SQLAlchemy-1.1.13:\n",
      "      Successfully uninstalled SQLAlchemy-1.1.13\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.2.1\n",
      "    Uninstalling scipy-1.2.1:\n",
      "      Successfully uninstalled scipy-1.2.1\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Successfully installed Logbook-1.5.3 alembic-1.7.7 alphalens-0.3.2 bcolz-0.12.1 bottleneck-1.3.5 contextlib2-21.6.0 cyordereddict-1.0.0 empyrical-0.5.5 graphviz-0.9 importlib-metadata-4.8.3 importlib-resources-5.4.0 intervaltree-3.1.0 lru-dict-1.1.8 multipledispatch-0.6.0 numpy-1.14.5 pandas-0.18.1 pandas-datareader-0.5.0 plotly-2.2.3 requests-file-1.5.1 requests-ftp-0.3.1 scipy-1.0.0 shap-0.25.2 sortedcontainers-2.4.0 sqlalchemy-1.4.40 tables-3.6.1 typing-extensions-4.1.1 zipline-1.2.0 zipp-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install --quiet -r requirements.txt\n",
    "!{sys.executable} -m pip install --upgrade setuptools\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import project_helper\n",
    "from zipline.data import bundles\n",
    "\n",
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..', 'data', 'module_4_quizzes_eod')\n",
    "\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], project_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(project_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(project_helper.EOD_BUNDLE_NAME)\n",
    "engine = project_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)\n",
    "\n",
    "def get_pricing(data_portal, trading_calendar, assets, start_date, end_date, field='close'):\n",
    "    end_dt = pd.Timestamp(end_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "    start_dt = pd.Timestamp(start_date.strftime('%Y-%m-%d'), tz='UTC', offset='C')\n",
    "\n",
    "    end_loc = trading_calendar.closes.index.get_loc(end_dt)\n",
    "    start_loc = trading_calendar.closes.index.get_loc(start_dt)\n",
    "\n",
    "    return data_portal.get_history_window(\n",
    "        assets=assets,\n",
    "        end_dt=end_dt,\n",
    "        bar_count=end_loc - start_loc,\n",
    "        frequency='1d',\n",
    "        field=field,\n",
    "        data_frequency='daily')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Factors\n",
    "\n",
    "- We'll use the same factors we have been using in the lessons about alpha factor research.  Factors can be features that we feed into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean_Reversion_Sector_Neutral_Smoothed</th>\n",
       "      <th>Momentum_1YR</th>\n",
       "      <th>Overnight_Sentiment_Smoothed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-03 00:00:00+00:00</th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <td>-0.262769</td>\n",
       "      <td>-1.207978</td>\n",
       "      <td>-1.485669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <td>0.099926</td>\n",
       "      <td>1.713471</td>\n",
       "      <td>0.919350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <td>1.669138</td>\n",
       "      <td>-1.535061</td>\n",
       "      <td>1.507733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <td>1.698746</td>\n",
       "      <td>1.193111</td>\n",
       "      <td>-1.367992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.250063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mean_Reversion_Sector_Neutral_Smoothed  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                                  -0.262769   \n",
       "                          Equity(1 [AAL])                                 0.099926   \n",
       "                          Equity(2 [AAP])                                 1.669138   \n",
       "                          Equity(3 [AAPL])                                1.698746   \n",
       "                          Equity(4 [ABBV])                                     NaN   \n",
       "\n",
       "                                            Momentum_1YR  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])        -1.207978   \n",
       "                          Equity(1 [AAL])       1.713471   \n",
       "                          Equity(2 [AAP])      -1.535061   \n",
       "                          Equity(3 [AAPL])      1.193111   \n",
       "                          Equity(4 [ABBV])           NaN   \n",
       "\n",
       "                                            Overnight_Sentiment_Smoothed  \n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                        -1.485669  \n",
       "                          Equity(1 [AAL])                       0.919350  \n",
       "                          Equity(2 [AAP])                       1.507733  \n",
       "                          Equity(3 [AAPL])                     -1.367992  \n",
       "                          Equity(4 [ABBV])                     -0.250063  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zipline.pipeline.factors import CustomFactor, DailyReturns, Returns, SimpleMovingAverage\n",
    "from zipline.pipeline.data import USEquityPricing\n",
    "\n",
    "factor_start_date = universe_end_date - pd.DateOffset(years=3, days=2)\n",
    "sector = project_helper.Sector()\n",
    "\n",
    "def momentum_1yr(window_length, universe, sector):\n",
    "    return Returns(window_length=window_length, mask=universe) \\\n",
    "        .demean(groupby=sector) \\\n",
    "        .rank() \\\n",
    "        .zscore()\n",
    "\n",
    "def mean_reversion_5day_sector_neutral(window_length, universe, sector):\n",
    "    return -Returns(window_length=window_length, mask=universe) \\\n",
    "        .demean(groupby=sector) \\\n",
    "        .rank() \\\n",
    "        .zscore()\n",
    "\n",
    "def mean_reversion_5day_sector_neutral_smoothed(window_length, universe, sector):\n",
    "    unsmoothed_factor = mean_reversion_5day_sector_neutral(window_length, universe, sector)\n",
    "    return SimpleMovingAverage(inputs=[unsmoothed_factor], window_length=window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()\n",
    "\n",
    "class CTO(Returns):\n",
    "    \"\"\"\n",
    "    Computes the overnight return, per hypothesis from\n",
    "    https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2554010\n",
    "    \"\"\"\n",
    "    inputs = [USEquityPricing.open, USEquityPricing.close]\n",
    "    \n",
    "    def compute(self, today, assets, out, opens, closes):\n",
    "        \"\"\"\n",
    "        The opens and closes matrix is 2 rows x N assets, with the most recent at the bottom.\n",
    "        As such, opens[-1] is the most recent open, and closes[0] is the earlier close\n",
    "        \"\"\"\n",
    "        out[:] = (opens[-1] - closes[0]) / closes[0]\n",
    "\n",
    "        \n",
    "class TrailingOvernightReturns(Returns):\n",
    "    \"\"\"\n",
    "    Sum of trailing 1m O/N returns\n",
    "    \"\"\"\n",
    "    window_safe = True\n",
    "    \n",
    "    def compute(self, today, asset_ids, out, cto):\n",
    "        out[:] = np.nansum(cto, axis=0)\n",
    "\n",
    "        \n",
    "def overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    cto_out = CTO(mask=universe, window_length=cto_window_length)\n",
    "    return TrailingOvernightReturns(inputs=[cto_out], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()\n",
    "\n",
    "def overnight_sentiment_smoothed(cto_window_length, trail_overnight_returns_window_length, universe):\n",
    "    unsmoothed_factor = overnight_sentiment(cto_window_length, trail_overnight_returns_window_length, universe)\n",
    "    return SimpleMovingAverage(inputs=[unsmoothed_factor], window_length=trail_overnight_returns_window_length) \\\n",
    "        .rank() \\\n",
    "        .zscore()\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500)\n",
    "sector = project_helper.Sector()\n",
    "\n",
    "pipeline = Pipeline(screen=universe)\n",
    "pipeline.add(\n",
    "    momentum_1yr(252, universe, sector),\n",
    "    'Momentum_1YR')\n",
    "pipeline.add(\n",
    "    mean_reversion_5day_sector_neutral_smoothed(20, universe, sector),\n",
    "    'Mean_Reversion_Sector_Neutral_Smoothed')\n",
    "pipeline.add(\n",
    "    overnight_sentiment_smoothed(2, 10, universe),\n",
    "    'Overnight_Sentiment_Smoothed')\n",
    "\n",
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "\n",
    "all_factors.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop here and continue with the lesson section titled \"Features\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Quant Features\n",
    "\n",
    "* stock volatility: zipline has a custom factor called AnnualizedVolatility.  The [source code is here](https://github.com/quantopian/zipline/blob/master/zipline/pipeline/factors/basic.py) and also pasted below:\n",
    "\n",
    "```\n",
    "class AnnualizedVolatility(CustomFactor):\n",
    "    \"\"\"\n",
    "    Volatility. The degree of variation of a series over time as measured by\n",
    "    the standard deviation of daily returns.\n",
    "    https://en.wikipedia.org/wiki/Volatility_(finance)\n",
    "    **Default Inputs:** :data:`zipline.pipeline.factors.Returns(window_length=2)`  # noqa\n",
    "    Parameters\n",
    "    ----------\n",
    "    annualization_factor : float, optional\n",
    "        The number of time units per year. Defaults is 252, the number of NYSE\n",
    "        trading days in a normal year.\n",
    "    \"\"\"\n",
    "    inputs = [Returns(window_length=2)]\n",
    "    params = {'annualization_factor': 252.0}\n",
    "    window_length = 252\n",
    "\n",
    "    def compute(self, today, assets, out, returns, annualization_factor):\n",
    "        out[:] = nanstd(returns, axis=0) * (annualization_factor ** .5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnualizedVolatility((Returns((USEquityPricing.close::float64,), window_length=2),), window_length=252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zipline.pipeline.factors import AnnualizedVolatility\n",
    "AnnualizedVolatility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "We can see that the returns `window_length` is 2, because we're dealing with daily returns, which are calculated as the percent change from one day to the following day (2 days).  The `AnnualizedVolatility` `window_length` is 252 by default, because it's the one-year volatility.  Try to adjust the call to the constructor of `AnnualizedVolatility` so that this represents one-month volatility (still annualized, but calculated over a time window of 20 trading days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnualizedVolatility((Returns((USEquityPricing.close::float64,), window_length=2),), window_length=20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "AnnualizedVolatility(window_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Create one-month and six-month annualized volatility.\n",
    "Create `AnnualizedVolatility` objects for 20 day and 120 day (one month and six-month) time windows.  Remember to set the `mask` parameter to the `universe` object created earlier (this filters the stocks to match the list in the `universe`).  Convert these to ranks, and then convert the ranks to zscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "volatility_20d = AnnualizedVolatility(window_length=20, mask=universe).rank().zscore()\n",
    "volatility_120d = AnnualizedVolatility(window_length=120, mask=universe).rank().zscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(volatility_20d, 'volatility_20d')\n",
    "pipeline.add(volatility_120d, 'volatility_120d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Average Dollar Volume feature\n",
    "We've been using [AverageDollarVolume](http://www.zipline.io/appendix.html#zipline.pipeline.factors.AverageDollarVolume) to choose the stock universe based on stocks that have the highest dollar volume.  We can also use it as a feature that is input into a predictive model.  \n",
    "Use 20 day and 120 day `window_length` for average dollar volume.  Then rank it and convert to a zscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"already imported earlier, but shown here for reference\"\"\"\n",
    "#from zipline.pipeline.factors import AverageDollarVolume \n",
    "\n",
    "# TODO: 20-day and 120 day average dollar volume\n",
    "adv_20d = AverageDollarVolume(window_length=20, mask=universe).rank().zscore()\n",
    "adv_120d = AverageDollarVolume(window_length=120, mask=universe).rank().zscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add average dollar volume features to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(adv_20d, 'adv_20d')\n",
    "pipeline.add(adv_120d, 'adv_120d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Regime Features\n",
    "We are going to try to capture market-wide regimes:  Market-wide means we'll look at the aggregate movement of the universe of stocks.\n",
    "\n",
    "High and low dispersion: dispersion is looking at the dispersion (standard deviation) of the cross section of all stocks at each period of time (on each day).  We'll inherit from [CustomFactor](http://www.zipline.io/appendix.html?highlight=customfactor#zipline.pipeline.CustomFactor).  We'll feed in [DailyReturns](http://www.zipline.io/appendix.html?highlight=dailyreturns#zipline.pipeline.factors.DailyReturns) as the `inputs`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "If the `inputs` to our market dispersion factor are the daily returns, and we plan to calculate the market dispersion on each day, what should be the `window_length` of the market dispersion class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer  \n",
    "window_length = 1, because each row of the input data represents returns (not stock prices).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: market dispersion feature\n",
    "Create a class that inherits from `CustomFactor`.  Override the `compute` function to calculate the population standard deviation of all the stocks over a specified window of time.\n",
    "\n",
    "**mean returns**\n",
    "\n",
    "$\\mu = \\sum_{t=0}^{T}\\sum_{i=1}^{N}r_{i,t}$\n",
    "\n",
    "**Market Dispersion**\n",
    "\n",
    "$\\sqrt{\\frac{1}{T} \\sum_{t=0}^{T}  \\frac{1}{N}\\sum_{i=1}^{N}(r_{i,t} - \\mu)^2}$\n",
    "\n",
    "Use [numpy.nanmean](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.nanmean.html) to calculate the average market return $\\mu$ and to calculate the average of the squared differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDispersion(CustomFactor):\n",
    "    inputs = [DailyReturns()]\n",
    "    window_length = 1\n",
    "    window_safe = True\n",
    "\n",
    "    def compute(self, today, assets, out, returns):\n",
    "        \n",
    "        # TODO: calculate average returns\n",
    "        mean_returns = np.nanmean(returns)\n",
    "        \n",
    "        #TODO: calculate standard deviation of returns\n",
    "        out[:] = np.sqrt(np.nanmean((returns - mean_returns)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "\n",
    "Create the MarketDispersion object.  Apply two separate smoothing operations using [SimpleMovingAverage](https://www.zipline.io/appendix.html?highlight=simplemovingaverage#zipline.pipeline.factors.SimpleMovingAverage).  One with a one-month window, and another with a 6-month window.  Add both to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create MarketDispersion object\n",
    "dispersion = MarketDispersion(mask=universe)\n",
    "\n",
    "# TODO: apply one-month simple moving average\n",
    "dispersion_20d = SimpleMovingAverage(inputs=[dispersion], window_length=20)\n",
    "\n",
    "# TODO: apply 6-month simple moving average\n",
    "dispersion_120d = SimpleMovingAverage(inputs=[dispersion], window_length=120)\n",
    "\n",
    "# Add to pipeline\n",
    "pipeline.add(dispersion_20d, 'dispersion_20d')\n",
    "pipeline.add(dispersion_120d, 'dispersion_120d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Market volatility feature\n",
    "* High and low volatility  \n",
    "We'll also build a class for market volatility, which inherits from [CustomFactor](http://www.zipline.io/appendix.html?highlight=customfactor#zipline.pipeline.CustomFactor).  This will measure the standard deviation of the returns of the \"market\".  In this case, we're approximating the \"market\" as the equal weighted average return of all the stocks in the stock universe.\n",
    "\n",
    "##### Market return\n",
    "$r_{m,t} = \\frac{1}{N}\\sum_{i=1}^{N}r_{i,t}$ for each day $t$ in `window_length`.  \n",
    "\n",
    "##### Average market return\n",
    "Also calculate the average market return over the `window_length` $T$ of days:  \n",
    "$\\mu_{m} = \\frac{1}{T}\\sum_{t=1}^{T} r_{m,t}$\n",
    "\n",
    "#### Standard deviation of market return\n",
    "Then calculate the standard deviation of the market return  \n",
    "$\\sigma_{m,t} = \\sqrt{252 \\times \\frac{1}{N} \\sum_{t=1}^{T}(r_{m,t} - \\mu_{m})^2 } $ \n",
    "\n",
    "##### Hints\n",
    "* Please use [numpy.nanmean](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.nanmean.html) so that it ignores null values.\n",
    "* When using `numpy.nanmean`:  \n",
    "axis=0 will calculate one average for every column (think of it like creating a new row in a spreadsheet)  \n",
    "axis=1 will calculate one average for every row (think of it like creating a new column in a spreadsheet)  \n",
    "* The returns data in `compute` has one day in each row, and one stock in each column.\n",
    "* Notice that we defined a dictionary `params` that has a key `annualization_factor`.  This `annualization_factor` can be used as a regular variable, and you'll be using it in the `compute` function.  This is also done in the definition of AnnualizedVolatility (as seen earlier in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketVolatility(CustomFactor):\n",
    "    inputs = [DailyReturns()]\n",
    "    window_length = 1  # We'll want to set this in the constructor when creating the object.\n",
    "    window_safe = True\n",
    "    params = {'annualization_factor': 252.0}\n",
    "    \n",
    "    def compute(self, today, assets, out, returns, annualization_factor):\n",
    "        \n",
    "        # TODO\n",
    "        \"\"\" \n",
    "        For each row (each row represents one day of returns), \n",
    "        calculate the average of the cross-section of stock returns\n",
    "        So that market_returns has one value for each day in the window_length\n",
    "        So choose the appropriate axis (please see hints above)\n",
    "        \"\"\"\n",
    "        mkt_returns = np.nanmean(returns, axis=1) \n",
    "        \n",
    "        # TODO\n",
    "        # Calculate the mean of market returns\n",
    "        mkt_returns_mu = np.nanmean(mkt_returns)\n",
    "        \n",
    "        # TODO\n",
    "        # Calculate the standard deviation of the market returns, then annualize them.\n",
    "        out[:] = np.sqrt(annualization_factor * np.nanmean((mkt_returns-mkt_returns_mu)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create market volatility features using one month and six-month windows\n",
    "market_vol_20d = MarketVolatility(window_length=20, mask=universe)\n",
    "market_vol_120d = MarketVolatility(window_length=120, mask=universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add market volatility features to pipeline\n",
    "pipeline.add(market_vol_20d, 'market_vol_20d')\n",
    "pipeline.add(market_vol_120d, 'market_vol_120d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop here and continue with the lesson section \"Sector and Industry\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector and Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add sector code\n",
    "\n",
    "Note that after we run the pipeline and get the data in a dataframe, we can work on enhancing the sector code feature with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add(sector, 'sector_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipeline to calculate features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean_Reversion_Sector_Neutral_Smoothed</th>\n",
       "      <th>Momentum_1YR</th>\n",
       "      <th>Overnight_Sentiment_Smoothed</th>\n",
       "      <th>adv_120d</th>\n",
       "      <th>adv_20d</th>\n",
       "      <th>dispersion_120d</th>\n",
       "      <th>dispersion_20d</th>\n",
       "      <th>market_vol_120d</th>\n",
       "      <th>market_vol_20d</th>\n",
       "      <th>sector_code</th>\n",
       "      <th>volatility_120d</th>\n",
       "      <th>volatility_20d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-03 00:00:00+00:00</th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <td>-0.262769</td>\n",
       "      <td>-1.207978</td>\n",
       "      <td>-1.485669</td>\n",
       "      <td>1.338573</td>\n",
       "      <td>1.397411</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.836546</td>\n",
       "      <td>-1.219809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <td>0.099926</td>\n",
       "      <td>1.713471</td>\n",
       "      <td>0.919350</td>\n",
       "      <td>1.139994</td>\n",
       "      <td>1.081155</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>3</td>\n",
       "      <td>1.639924</td>\n",
       "      <td>1.566220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <td>1.669138</td>\n",
       "      <td>-1.535061</td>\n",
       "      <td>1.507733</td>\n",
       "      <td>-0.301547</td>\n",
       "      <td>-0.919350</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>8</td>\n",
       "      <td>1.072400</td>\n",
       "      <td>-1.470404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <td>1.698746</td>\n",
       "      <td>1.193111</td>\n",
       "      <td>-1.367992</td>\n",
       "      <td>1.728377</td>\n",
       "      <td>1.728377</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>1</td>\n",
       "      <td>1.050289</td>\n",
       "      <td>1.617813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.250063</td>\n",
       "      <td>-1.728377</td>\n",
       "      <td>-1.647475</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mean_Reversion_Sector_Neutral_Smoothed  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                                  -0.262769   \n",
       "                          Equity(1 [AAL])                                 0.099926   \n",
       "                          Equity(2 [AAP])                                 1.669138   \n",
       "                          Equity(3 [AAPL])                                1.698746   \n",
       "                          Equity(4 [ABBV])                                     NaN   \n",
       "\n",
       "                                            Momentum_1YR  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])        -1.207978   \n",
       "                          Equity(1 [AAL])       1.713471   \n",
       "                          Equity(2 [AAP])      -1.535061   \n",
       "                          Equity(3 [AAPL])      1.193111   \n",
       "                          Equity(4 [ABBV])           NaN   \n",
       "\n",
       "                                            Overnight_Sentiment_Smoothed  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                        -1.485669   \n",
       "                          Equity(1 [AAL])                       0.919350   \n",
       "                          Equity(2 [AAP])                       1.507733   \n",
       "                          Equity(3 [AAPL])                     -1.367992   \n",
       "                          Equity(4 [ABBV])                     -0.250063   \n",
       "\n",
       "                                            adv_120d   adv_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])     1.338573  1.397411   \n",
       "                          Equity(1 [AAL])   1.139994  1.081155   \n",
       "                          Equity(2 [AAP])  -0.301547 -0.919350   \n",
       "                          Equity(3 [AAPL])  1.728377  1.728377   \n",
       "                          Equity(4 [ABBV]) -1.728377 -1.647475   \n",
       "\n",
       "                                            dispersion_120d  dispersion_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])            0.013270        0.011178   \n",
       "                          Equity(1 [AAL])          0.013270        0.011178   \n",
       "                          Equity(2 [AAP])          0.013270        0.011178   \n",
       "                          Equity(3 [AAPL])         0.013270        0.011178   \n",
       "                          Equity(4 [ABBV])         0.014595        0.014595   \n",
       "\n",
       "                                            market_vol_120d  market_vol_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])            0.127654        0.135452   \n",
       "                          Equity(1 [AAL])          0.127654        0.135452   \n",
       "                          Equity(2 [AAP])          0.127654        0.135452   \n",
       "                          Equity(3 [AAPL])         0.127654        0.135452   \n",
       "                          Equity(4 [ABBV])         0.127654        0.135452   \n",
       "\n",
       "                                            sector_code  volatility_120d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])               0        -0.836546   \n",
       "                          Equity(1 [AAL])             3         1.639924   \n",
       "                          Equity(2 [AAP])             8         1.072400   \n",
       "                          Equity(3 [AAPL])            1         1.050289   \n",
       "                          Equity(4 [ABBV])            0              NaN   \n",
       "\n",
       "                                            volatility_20d  \n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])          -1.219809  \n",
       "                          Equity(1 [AAL])         1.566220  \n",
       "                          Equity(2 [AAP])        -1.470404  \n",
       "                          Equity(3 [AAPL])        1.617813  \n",
       "                          Equity(4 [ABBV])             NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_factors = engine.run_pipeline(pipeline, factor_start_date, universe_end_date)\n",
    "all_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode sector\n",
    "\n",
    "Let's get all the unique sector codes.  Then we'll use the `==` comparison operator to check when the sector code equals a particular value.  This returns a series of True/False values.  For some functions that we'll use in a later lesson, it's easier to work with numbers instead of booleans.  We can convert the booleans to type int.  So False becomes 0, and 1 becomes True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_code_l = set(all_factors['sector_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-03 00:00:00+00:00  Equity(0 [A])        True\n",
       "                           Equity(1 [AAL])     False\n",
       "                           Equity(2 [AAP])     False\n",
       "                           Equity(3 [AAPL])    False\n",
       "                           Equity(4 [ABBV])     True\n",
       "Name: sector_code, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_0 = all_factors['sector_code'] == 0\n",
    "sector_0[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013-01-03 00:00:00+00:00  Equity(0 [A])       1\n",
       "                           Equity(1 [AAL])     0\n",
       "                           Equity(2 [AAP])     0\n",
       "                           Equity(3 [AAPL])    0\n",
       "                           Equity(4 [ABBV])    1\n",
       "Name: sector_code, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_0_numeric = sector_0.astype(int)\n",
    "sector_0_numeric[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: One-hot encode sector\n",
    "Choose column names that look like \"sector_code_0\", \"sector_code_1\" etc.  Store the values as 1 when the row matches the sector code of the column, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: one-hot encode sector and store into dataframe\n",
    "for s in sector_code_l:\n",
    "    all_factors[f'sector_code_{s}'] = (all_factors['sector_code'] == s).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean_Reversion_Sector_Neutral_Smoothed</th>\n",
       "      <th>Momentum_1YR</th>\n",
       "      <th>Overnight_Sentiment_Smoothed</th>\n",
       "      <th>adv_120d</th>\n",
       "      <th>adv_20d</th>\n",
       "      <th>dispersion_120d</th>\n",
       "      <th>dispersion_20d</th>\n",
       "      <th>market_vol_120d</th>\n",
       "      <th>market_vol_20d</th>\n",
       "      <th>sector_code</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_code_2</th>\n",
       "      <th>sector_code_3</th>\n",
       "      <th>sector_code_4</th>\n",
       "      <th>sector_code_5</th>\n",
       "      <th>sector_code_6</th>\n",
       "      <th>sector_code_7</th>\n",
       "      <th>sector_code_8</th>\n",
       "      <th>sector_code_9</th>\n",
       "      <th>sector_code_10</th>\n",
       "      <th>sector_code_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-03 00:00:00+00:00</th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <td>-0.262769</td>\n",
       "      <td>-1.207978</td>\n",
       "      <td>-1.485669</td>\n",
       "      <td>1.338573</td>\n",
       "      <td>1.397411</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <td>0.099926</td>\n",
       "      <td>1.713471</td>\n",
       "      <td>0.919350</td>\n",
       "      <td>1.139994</td>\n",
       "      <td>1.081155</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <td>1.669138</td>\n",
       "      <td>-1.535061</td>\n",
       "      <td>1.507733</td>\n",
       "      <td>-0.301547</td>\n",
       "      <td>-0.919350</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <td>1.698746</td>\n",
       "      <td>1.193111</td>\n",
       "      <td>-1.367992</td>\n",
       "      <td>1.728377</td>\n",
       "      <td>1.728377</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.250063</td>\n",
       "      <td>-1.728377</td>\n",
       "      <td>-1.647475</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.127654</td>\n",
       "      <td>0.135452</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mean_Reversion_Sector_Neutral_Smoothed  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                                  -0.262769   \n",
       "                          Equity(1 [AAL])                                 0.099926   \n",
       "                          Equity(2 [AAP])                                 1.669138   \n",
       "                          Equity(3 [AAPL])                                1.698746   \n",
       "                          Equity(4 [ABBV])                                     NaN   \n",
       "\n",
       "                                            Momentum_1YR  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])        -1.207978   \n",
       "                          Equity(1 [AAL])       1.713471   \n",
       "                          Equity(2 [AAP])      -1.535061   \n",
       "                          Equity(3 [AAPL])      1.193111   \n",
       "                          Equity(4 [ABBV])           NaN   \n",
       "\n",
       "                                            Overnight_Sentiment_Smoothed  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                        -1.485669   \n",
       "                          Equity(1 [AAL])                       0.919350   \n",
       "                          Equity(2 [AAP])                       1.507733   \n",
       "                          Equity(3 [AAPL])                     -1.367992   \n",
       "                          Equity(4 [ABBV])                     -0.250063   \n",
       "\n",
       "                                            adv_120d   adv_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])     1.338573  1.397411   \n",
       "                          Equity(1 [AAL])   1.139994  1.081155   \n",
       "                          Equity(2 [AAP])  -0.301547 -0.919350   \n",
       "                          Equity(3 [AAPL])  1.728377  1.728377   \n",
       "                          Equity(4 [ABBV]) -1.728377 -1.647475   \n",
       "\n",
       "                                            dispersion_120d  dispersion_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])            0.013270        0.011178   \n",
       "                          Equity(1 [AAL])          0.013270        0.011178   \n",
       "                          Equity(2 [AAP])          0.013270        0.011178   \n",
       "                          Equity(3 [AAPL])         0.013270        0.011178   \n",
       "                          Equity(4 [ABBV])         0.014595        0.014595   \n",
       "\n",
       "                                            market_vol_120d  market_vol_20d  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])            0.127654        0.135452   \n",
       "                          Equity(1 [AAL])          0.127654        0.135452   \n",
       "                          Equity(2 [AAP])          0.127654        0.135452   \n",
       "                          Equity(3 [AAPL])         0.127654        0.135452   \n",
       "                          Equity(4 [ABBV])         0.127654        0.135452   \n",
       "\n",
       "                                            sector_code       ...        \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])               0       ...         \n",
       "                          Equity(1 [AAL])             3       ...         \n",
       "                          Equity(2 [AAP])             8       ...         \n",
       "                          Equity(3 [AAPL])            1       ...         \n",
       "                          Equity(4 [ABBV])            0       ...         \n",
       "\n",
       "                                            sector_code_2  sector_code_3  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                 0              0   \n",
       "                          Equity(1 [AAL])               0              1   \n",
       "                          Equity(2 [AAP])               0              0   \n",
       "                          Equity(3 [AAPL])              0              0   \n",
       "                          Equity(4 [ABBV])              0              0   \n",
       "\n",
       "                                            sector_code_4  sector_code_5  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                 0              0   \n",
       "                          Equity(1 [AAL])               0              0   \n",
       "                          Equity(2 [AAP])               0              0   \n",
       "                          Equity(3 [AAPL])              0              0   \n",
       "                          Equity(4 [ABBV])              0              0   \n",
       "\n",
       "                                            sector_code_6  sector_code_7  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                 0              0   \n",
       "                          Equity(1 [AAL])               0              0   \n",
       "                          Equity(2 [AAP])               0              0   \n",
       "                          Equity(3 [AAPL])              0              0   \n",
       "                          Equity(4 [ABBV])              0              0   \n",
       "\n",
       "                                            sector_code_8  sector_code_9  \\\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                 0              0   \n",
       "                          Equity(1 [AAL])               0              0   \n",
       "                          Equity(2 [AAP])               1              0   \n",
       "                          Equity(3 [AAPL])              0              0   \n",
       "                          Equity(4 [ABBV])              0              0   \n",
       "\n",
       "                                            sector_code_10  sector_code_-1  \n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                  0               0  \n",
       "                          Equity(1 [AAL])                0               0  \n",
       "                          Equity(2 [AAP])                0               0  \n",
       "                          Equity(3 [AAPL])               0               0  \n",
       "                          Equity(4 [ABBV])               0               0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_factors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop here and continue with the lesson section \"Date Parts\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Parts\n",
    "* We will make features that might capture trader/investor behavior due to calendar anomalies.\n",
    "* We can get the dates from the index of the dataframe that is returned from running the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing index of dates\n",
    "* Note that we can access the date index. using `Dataframe.index.get_level_values(0)`, since the date is stored as index level 0, and the asset name is stored in index level 1.  This is of type [DateTimeIndex](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-03', '2013-01-03', '2013-01-03', '2013-01-03',\n",
       "               '2013-01-03', '2013-01-03', '2013-01-03', '2013-01-03',\n",
       "               '2013-01-03', '2013-01-03',\n",
       "               ...\n",
       "               '2016-01-05', '2016-01-05', '2016-01-05', '2016-01-05',\n",
       "               '2016-01-05', '2016-01-05', '2016-01-05', '2016-01-05',\n",
       "               '2016-01-05', '2016-01-05'],\n",
       "              dtype='datetime64[ns, UTC]', length=363734, freq=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_factors.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [DateTimeIndex attributes](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html)\n",
    "\n",
    "* The `month` attribute is a numpy array with a 1 for January, 2 for February ... 12 for December etc.  \n",
    "* We can use a comparison operator such as `==` to return True or False.\n",
    "\n",
    "* It's usually easier to have all data of a similar type (numeric), so we recommend converting booleans to integers.  \n",
    "The numpy ndarray has a function `.astype()` that can cast the data to a specified type.  \n",
    "For instance, `astype(int)` converts False to 0 and True to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[ True  True  True ...  True  True  True]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(all_factors.index.get_level_values(0).month)\n",
    "print(all_factors.index.get_level_values(0).month == 1)\n",
    "print( (all_factors.index.get_level_values(0).month == 1).astype(int) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "* Create a numpy array that has 1 when the month is January, and 0 otherwise.  Store it as a column in the all_factors dataframe.\n",
    "* Add another similar column to indicate when the month is December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a feature that indicate whether it's January\n",
    "all_factors['is_January'] = (all_factors.index.get_level_values(0).month == 1).astype(int)\n",
    "\n",
    "# TODO: create a feature to indicate whether it's December\n",
    "all_factors['is_December'] = (all_factors.index.get_level_values(0).month == 12).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekday, quarter\n",
    "* add columns to the all_factors dataframe that specify the weekday, quarter and year.\n",
    "* As you can see in the [documentation for DateTimeIndex](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html), `weekday`, `quarter`, and `year` are attributes that you can use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that 0 is for Monday, 4 is for Friday\n",
    "set(all_factors.index.get_level_values(0).weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1, Q2, Q3 and Q4 are represented by integers too\n",
    "set(all_factors.index.get_level_values(0).quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2013, 2014, 2015, 2016}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_factors.index.get_level_values(0).year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "Add features for weekday, quarter and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "all_factors['weekday'] = all_factors.index.get_level_values(0).weekday\n",
    "all_factors['quarter'] = all_factors.index.get_level_values(0).quarter\n",
    "all_factors['year'] = all_factors.index.get_level_values(0).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start and end-of features\n",
    "\n",
    "* The start and end of the week, month, and quarter may have structural differences in trading activity.\n",
    "* [Pandas.date_range](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.date_range.html) takes the start_date, end_date, and frequency.\n",
    "* The [frequency](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases) for end of month is `BM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-31', '2013-02-28', '2013-03-29', '2013-04-30',\n",
       "               '2013-05-31', '2013-06-28', '2013-07-31', '2013-08-30',\n",
       "               '2013-09-30', '2013-10-31', '2013-11-29', '2013-12-31',\n",
       "               '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n",
       "               '2014-05-30', '2014-06-30', '2014-07-31', '2014-08-29',\n",
       "               '2014-09-30', '2014-10-31', '2014-11-28', '2014-12-31',\n",
       "               '2015-01-30', '2015-02-27', '2015-03-31', '2015-04-30',\n",
       "               '2015-05-29', '2015-06-30', '2015-07-31', '2015-08-31',\n",
       "               '2015-09-30', '2015-10-30', '2015-11-30', '2015-12-31'],\n",
       "              dtype='datetime64[ns, UTC]', freq='BM')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "tmp = pd.date_range(start=factor_start_date, end=universe_end_date, freq='BM')\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Create a DatetimeIndex that stores the dates which are the last business day of each month.  \n",
    "Use the `.isin` function, passing in these last days of the month, to create a series of booleans.  \n",
    "Convert the booleans to integers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-31', '2013-02-28', '2013-03-29', '2013-04-30',\n",
       "               '2013-05-31', '2013-06-28', '2013-07-31', '2013-08-30',\n",
       "               '2013-09-30', '2013-10-31', '2013-11-29', '2013-12-31',\n",
       "               '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n",
       "               '2014-05-30', '2014-06-30', '2014-07-31', '2014-08-29',\n",
       "               '2014-09-30', '2014-10-31', '2014-11-28', '2014-12-31',\n",
       "               '2015-01-30', '2015-02-27', '2015-03-31', '2015-04-30',\n",
       "               '2015-05-29', '2015-06-30', '2015-07-31', '2015-08-31',\n",
       "               '2015-09-30', '2015-10-30', '2015-11-30', '2015-12-31'],\n",
       "              dtype='datetime64[ns, UTC]', freq='BM')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_day_of_month = pd.date_range(start=factor_start_date, end=universe_end_date, freq='BM')\n",
    "last_day_of_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_month_end = all_factors.index.get_level_values(0).isin(last_day_of_month)\n",
    "tmp_month_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_month_end_int = tmp_month_end.astype(int)\n",
    "tmp_month_end_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factors['month_end'] = tmp_month_end_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Start of Month\n",
    "Create a feature that indicates the first business day of each month.\n",
    "\n",
    "**Hint:** The frequency for first business day of the month uses the code `BMS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: month_start feature\n",
    "first_day_of_month = pd.date_range(start=factor_start_date, end=universe_end_date, freq='BMS')\n",
    "all_factors['month_start'] = (all_factors.index.get_level_values(0).isin(first_day_of_month)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: Quarter end and quarter start\n",
    "\n",
    "Create features for the last business day of each quarter, and first business day of each quarter.  \n",
    "**Hint**: use `freq=BQ` for business day end of quarter, and `freq=BQS` for business day start of quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: qtr_end feature\n",
    "last_day_qtr = pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQ')\n",
    "all_factors['qtr_end'] = (all_factors.index.get_level_values(0).isin(last_day_qtr)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: qtr_start feature\n",
    "first_day_qtr = pd.date_range(start=factor_start_date, end=universe_end_date, freq='BQS')\n",
    "all_factors['qtr_start'] = (all_factors.index.get_level_values(0).isin(first_day_qtr)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mean_Reversion_Sector_Neutral_Smoothed',\n",
       " 'Momentum_1YR',\n",
       " 'Overnight_Sentiment_Smoothed',\n",
       " 'adv_120d',\n",
       " 'adv_20d',\n",
       " 'dispersion_120d',\n",
       " 'dispersion_20d',\n",
       " 'market_vol_120d',\n",
       " 'market_vol_20d',\n",
       " 'sector_code',\n",
       " 'volatility_120d',\n",
       " 'volatility_20d',\n",
       " 'sector_code_0',\n",
       " 'sector_code_1',\n",
       " 'sector_code_2',\n",
       " 'sector_code_3',\n",
       " 'sector_code_4',\n",
       " 'sector_code_5',\n",
       " 'sector_code_6',\n",
       " 'sector_code_7',\n",
       " 'sector_code_8',\n",
       " 'sector_code_9',\n",
       " 'sector_code_10',\n",
       " 'sector_code_-1',\n",
       " 'is_January',\n",
       " 'is_December',\n",
       " 'weekday',\n",
       " 'quarter',\n",
       " 'year',\n",
       " 'month_end',\n",
       " 'month_start',\n",
       " 'qtr_end',\n",
       " 'qtr_start']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_factors.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can skip the sector_code feature, since we one-hot encoded it into separate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Mean_Reversion_Sector_Neutral_Smoothed',\n",
    " 'Momentum_1YR',\n",
    " 'Overnight_Sentiment_Smoothed',\n",
    " 'adv_120d',\n",
    " 'adv_20d',\n",
    " 'dispersion_120d',\n",
    " 'dispersion_20d',\n",
    " 'market_vol_120d',\n",
    " 'market_vol_20d',\n",
    " #'sector_code', # removed sector_code\n",
    " 'volatility_120d',\n",
    " 'volatility_20d',\n",
    " 'sector_code_0',\n",
    " 'sector_code_1',\n",
    " 'sector_code_2',\n",
    " 'sector_code_3',\n",
    " 'sector_code_4',\n",
    " 'sector_code_5',\n",
    " 'sector_code_6',\n",
    " 'sector_code_7',\n",
    " 'sector_code_8',\n",
    " 'sector_code_9',\n",
    " 'sector_code_10',\n",
    " 'sector_code_-1',\n",
    " 'is_January',\n",
    " 'is_December',\n",
    " 'weekday',\n",
    " 'quarter',\n",
    " 'year',\n",
    " 'month_start',\n",
    " 'qtr_end',\n",
    " 'qtr_start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop here and continue to the lesson section \"Targets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targets (Labels)\n",
    "\n",
    "- We are going to try to predict the go forward 1-week return\n",
    "- Very important! Quantize the target. Why do we do this?\n",
    "  - Makes it market neutral return\n",
    "  - Normalizes changing volatility and dispersion over time\n",
    "  - Make the target robust to changes in market regimes\n",
    "- The factor we create is the trailing 5-day return.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create a separate pipeline to handle the target\n",
    "pipeline_target = Pipeline(screen=universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "We'll convert weekly returns into 2-quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantiles((Returns((USEquityPricing.close::float64,), window_length=5),), window_length=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_5d_2q = Returns(window_length=5, mask=universe).quantiles(2)\n",
    "return_5d_2q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_target.add(return_5d_2q, 'return_5d_2q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "Create another weekly return target that's converted to 5-quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>return_5d_2q</th>\n",
       "      <th>return_5d_5q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-03 00:00:00+00:00</th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            return_5d_2q  return_5d_5q\n",
       "2013-01-03 00:00:00+00:00 Equity(0 [A])                0             0\n",
       "                          Equity(1 [AAL])              1             1\n",
       "                          Equity(2 [AAP])              0             0\n",
       "                          Equity(3 [AAPL])             1             1\n",
       "                          Equity(4 [ABBV])            -1            -1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: create a target using 5-quantiles\n",
    "return_5d_5q = Returns(window_length=5, mask=universe).quantiles(5)\n",
    "\n",
    "# TODO: add the feature to the pipeline\n",
    "pipeline_target.add(return_5d_2q, 'return_5d_5q')\n",
    "\n",
    "# Let's run the pipeline to get the dataframe\n",
    "targets_df = engine.run_pipeline(pipeline_target, factor_start_date, universe_end_date)\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['return_5d_2q', 'return_5d_5q'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "[solution notebook](feature_engineering_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
